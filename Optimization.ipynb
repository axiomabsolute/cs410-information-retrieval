{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from operator import attrgetter\n",
    "from tabulate import tabulate\n",
    "from music21 import corpus\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from firms.graders import count_grader, log_count_grader, weighted_sum_grader_factory, log_weighted_sum_grader_factory, stem_counter_by_piece, log_weighted_sum_grader_weightless_factory\n",
    "from firms.stemmers import index_key_by_pitch, index_key_by_simple_pitch, index_key_by_interval, index_key_by_contour, index_key_by_rythm, index_key_by_normalized_rythm\n",
    "from firms.models import MemoryIRSystem, print_timing, flatten\n",
    "from firms.sql_irsystems import SqlIRSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-06 23:22:00.486892 Loading pieces\n"
     ]
    }
   ],
   "source": [
    "print_timing(\"Loading pieces\")\n",
    "piece_paths = flatten([\n",
    "    corpus.getComposer('bach', 'xml'),\n",
    "    corpus.getComposer('mozart', 'xml'),\n",
    "    corpus.getComposer('beethoven', 'xml'),\n",
    "    corpus.getComposer('schumann', 'xml')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_methods = {\n",
    "    'By Pitch': index_key_by_pitch,\n",
    "    'By Simple Pitch': index_key_by_simple_pitch,\n",
    "    'By Contour': index_key_by_contour,\n",
    "    'By Interval': index_key_by_interval,\n",
    "    'By Rythm': index_key_by_rythm,\n",
    "    'By Normal Rythm': index_key_by_normalized_rythm\n",
    "}\n",
    "\n",
    "weights = {'By Pitch': 2, 'By Simple Pitch': 1, 'By Interval': .2, 'By Contour': .1, 'By Rythm': .1, 'By Normal Rythm': .1}\n",
    "weights2 = {'By Pitch': 4.3, 'By Simple Pitch': 2.5, 'By Interval': 3.0, 'By Contour': -1.94, 'By Rythm': 1.36, 'By Normal Rythm': -2.85}\n",
    "scorer_methods = {\n",
    "    # 'Count': count_grader,\n",
    "    # 'Log Count': log_count_grader,\n",
    "    # 'Linear': weighted_sum_grader_factory(weights),\n",
    "    'LogLinar': log_weighted_sum_grader_factory(weights),\n",
    "    'LogLinear2': log_weighted_sum_grader_factory(weights2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-06 23:22:39.892950 Building IR system\n",
      "2017-11-06 23:22:39.895949 Sampling ranges for demonstration\n",
      "2017-11-06 23:23:12.261235 Done\n"
     ]
    }
   ],
   "source": [
    "print_timing(\"Building IR system\")\n",
    "# irsystem = MemoryIRSystem(index_methods, scorer_methods, piece_paths)\n",
    "\n",
    "sqlsystem = SqlIRSystem('example.db.sqlite', index_methods, scorer_methods, piece_paths, False)\n",
    "\n",
    "print_timing(\"Sampling ranges for demonstration\")\n",
    "sample_paths = random.sample(piece_paths, min(50, len(piece_paths)))\n",
    "sample_pieces = (corpus.parse(piece) for piece in sample_paths)\n",
    "sample_streams = []\n",
    "sample_details = []\n",
    "for piece in sample_pieces:\n",
    "    parts = list(piece.recurse().parts)\n",
    "    part = random.sample(parts, 1)[0]\n",
    "    num_of_measures = len(part.measures(0, None))\n",
    "    idx = random.randint(0, num_of_measures-5)\n",
    "    sample_streams.append(part.measures(idx, idx+4).recurse().notesAndRests)\n",
    "    sample_details.append((piece.metadata.title, part, idx))\n",
    "print_timing(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================\n",
      "Optimization\n",
      "==========================================================================\n",
      "2017-11-06 23:23:21.062047 Building linear model\n",
      "\t2017-11-06 23:23:21.062047 Querying bwv248.33-3.mxl (Tenor)\n",
      "\t2017-11-06 23:23:23.338577 Querying bwv421.mxl (Bass)\n",
      "\t2017-11-06 23:23:41.816420 Querying bwv177.5.mxl (Bass)\n",
      "\t2017-11-06 23:23:49.732160 Querying bwv384.mxl (Bass)\n",
      "\t2017-11-06 23:23:52.028255 Querying bwv52.6.mxl (Soprano)\n",
      "\t2017-11-06 23:23:57.104997 Querying bwv103.6.mxl (Alto)\n",
      "\t2017-11-06 23:24:11.711622 Querying bwv245.22.mxl (Alto)\n",
      "\t2017-11-06 23:24:22.339754 Querying bwv153.5.mxl (Tenor)\n",
      "\t2017-11-06 23:24:28.727255 Querying bwv156.6.mxl (Tenor)\n",
      "\t2017-11-06 23:24:35.801834 Querying bwv846.mxl (Piano)\n",
      "\t2017-11-06 23:25:01.840280 Querying movement1.mxl (Viola)\n",
      "\t2017-11-06 23:25:19.486589 Querying bwv287.mxl (Soprano)\n",
      "\t2017-11-06 23:25:21.829644 Querying bwv387.mxl (Tenor)\n",
      "\t2017-11-06 23:25:24.001366 Querying II. Aus meinen Tränen sprießen (MusicXML Part)\n",
      "\t2017-11-06 23:25:24.096866 Querying bwv341.mxl (Alto)\n",
      "\t2017-11-06 23:25:30.262867 Querying bwv270.mxl (Soprano)\n",
      "\t2017-11-06 23:25:32.937354 Querying bwv94.8.mxl (Alto)\n",
      "\t2017-11-06 23:25:35.830904 Querying bwv333.mxl (Bass)\n",
      "\t2017-11-06 23:25:53.698279 Querying bwv1.6.mxl (Alto)\n",
      "\t2017-11-06 23:26:06.575790 Querying bwv187.7.mxl (Alto)\n",
      "\t2017-11-06 23:26:08.220491 Querying bwv244.54.mxl (Bass)\n",
      "\t2017-11-06 23:26:14.586613 Querying bwv5.7.mxl (Soprano)\n",
      "\t2017-11-06 23:26:22.163934 Querying bwv342.mxl (Bass)\n",
      "\t2017-11-06 23:26:30.632068 Querying bwv361.mxl (Alto)\n",
      "\t2017-11-06 23:26:32.585124 Querying bwv169.7.mxl (Soprano)\n",
      "\t2017-11-06 23:26:35.255676 Querying bwv149.7.mxl (Trumpet 2)\n",
      "\t2017-11-06 23:26:36.421710 Querying String Quartet (Violoncello)\n",
      "\t2017-11-06 23:26:36.468209 Querying bwv126.6.mxl (Bass)\n",
      "\t2017-11-06 23:26:45.758852 Querying bwv85.6.mxl (Tenor)\n",
      "\t2017-11-06 23:26:56.318159 Querying bwv267.xml (Soprano)\n",
      "\t2017-11-06 23:27:05.871768 Querying bwv354.mxl (Bass)\n",
      "\t2017-11-06 23:27:16.150475 Querying bwv124.6.mxl (Bass)\n",
      "\t2017-11-06 23:27:32.567977 Querying bwv36.4-2.mxl (Alto)\n",
      "\t2017-11-06 23:27:39.547381 Querying bwv244.44.mxl (Alto)\n",
      "\t2017-11-06 23:27:45.060446 Querying bwv176.6.mxl (Bass)\n",
      "\t2017-11-06 23:27:50.699580 Querying bwv273.mxl (Alto)\n",
      "\t2017-11-06 23:27:58.963120 Querying bwv297.mxl (Bass)\n",
      "\t2017-11-06 23:28:11.302034 Querying bwv128.5.mxl (Horn 2)\n",
      "\t2017-11-06 23:28:16.409230 Querying bwv158.4.mxl (Bass)\n",
      "\t2017-11-06 23:28:35.464348 Querying bwv298.mxl (Alto)\n",
      "\t2017-11-06 23:28:37.994863 Querying bwv325.mxl (Soprano)\n",
      "\t2017-11-06 23:28:45.694991 Querying bwv303.mxl (Soprano)\n",
      "\t2017-11-06 23:28:52.980027 Querying bwv244.37.mxl (Alto)\n",
      "\t2017-11-06 23:29:07.046219 Querying bwv278.mxl (Soprano)\n",
      "\t2017-11-06 23:29:15.732768 Querying bwv407.mxl (Bass)\n",
      "\t2017-11-06 23:29:17.753266 Querying bwv248.42-s.mxl (Tenor)\n",
      "\t2017-11-06 23:29:18.918767 Querying bwv144.3.mxl (Soprano)\n",
      "\t2017-11-06 23:29:33.803180 Querying bwv174.5.mxl (Bass)\n",
      "\t2017-11-06 23:29:43.063251 Querying bwv344.mxl (Alto)\n",
      "\t2017-11-06 23:29:43.933754 Querying bwv146.8.mxl (Tenor)\n",
      "2017-11-06 23:29:54.648914 Done\n"
     ]
    }
   ],
   "source": [
    "print(\"==========================================================================\")\n",
    "print(\"Optimization\")\n",
    "print(\"==========================================================================\")\n",
    "\n",
    "print_timing(\"Building linear model\")\n",
    "tp_names = list(map(lambda x: x[0], sample_details))\n",
    "matches = []\n",
    "for detail,query in zip(sample_details, sample_streams):\n",
    "    print_timing(\"Querying %s (%s)\" % (detail[0], detail[1].partName), 1)\n",
    "    raw_results = list(sqlsystem.raw_query(query))\n",
    "    matches.append(stem_counter_by_piece(raw_results))\n",
    "print_timing(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tIgnoring II. Aus meinen Tränen sprießen\n",
      "\t\t\tIgnoring String Quartet\n",
      "      fun: 4.3125\n",
      " hess_inv: <6x6 LbfgsInvHessProduct with dtype=float64>\n",
      "      jac: array([ 0.,  0.,  0.,  0.,  0.,  0.])\n",
      "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
      "     nfev: 21\n",
      "      nit: 1\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 4.38148063,  4.38148063,  2.12716021,  0.46437347,  0.46437347,\n",
      "        0.46437347])\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import firms\n",
    "from firms import graders\n",
    "reload(graders)\n",
    "to_optimize = graders.log_weighted_sum_grader_weightless_factory(matches, tp_names, weights.keys())\n",
    "optimized = minimize(\n",
    "    to_optimize,\n",
    "    list(1 for i in weights.values()),\n",
    "    method='L-BFGS-B',\n",
    "    options={'eps': 1e-02},\n",
    "    bounds=tuple((0.01, None) for i in weights.items())\n",
    ")\n",
    "print(optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
